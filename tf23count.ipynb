{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJZCYK0OdLTdhecTiEUfha",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoho0529/TensorFlow/blob/main/tf23count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBa-emUGF2w2",
        "outputId": "2348e397-d55e-44f2-bb9f-99913af163ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer()\n",
            "  (0, 3)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 0)\t1\n",
            "  (1, 1)\t2\n",
            "  (1, 2)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 5)\t1\n",
            "['disk' 'format' 'hard' 'how' 'my' 'problems' 'to']\n",
            "[[1 1 1 1 1 0 1]\n",
            " [1 2 1 0 0 1 0]]\n",
            "['How to format my hard disk', 'Hard disk format format problems']\n"
          ]
        }
      ],
      "source": [
        "# 단어의 빈도수로 자연어 특징 추출\n",
        "# CountVectorizer : 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW 인코딩 벡터를 만든다.\n",
        "# TfidfVectorizer : CountVectorizer와 비슷하지만 TF-IDF 방식으로 단어의 가중치를 조정한 BOW 인코딩 벡터를 만든다.  BOW : Back Of Words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# CountVectorizer : 단순한 특징으로 corpus에서 단위별 등장횟수를 카운팅하여 수치벡터(BOW)화 함.\n",
        "# 단위는 임의적이다., 단어, 글자, 자소, 문서, 문장 등등 일 수 도 있다.\n",
        "content=['How to format my hard disk', 'Hard disk format format problems']\n",
        "\n",
        "\n",
        "count_vec = CountVectorizer(analyzer='word', min_df=1)\n",
        "print(count_vec)\n",
        "\n",
        "train = count_vec.fit_transform(raw_documents=content)\n",
        "print(train)\n",
        "print(count_vec.get_feature_names_out())   # BOW vector : token의 개수만큼 생성됨\n",
        "# ['disk' 'format' 'hard' 'how' 'my' 'problems' 'to']\n",
        "#    0       1        2     3     4       5       6    : 사전순으로 인덱스\n",
        "print(train.toarray())\n",
        "print(content)\n",
        "\n",
        "# 장점 : 쉽고 빠른 구축. 예상보다 문서의 특징을 잘 나타내어 전통적으로 활용됨.\n",
        "# 단점 : 문맥 의미 반영 문제. 희소 행렬 문제."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer : CountVectorizer의 단점을 해결하기 위한 기법\n",
        "# 특정 문서 내에서 특정 단어의 빈도인 TF(Term Frequecy) 와, 전체 문서 내에서 특정 단어의 빈도인 DF(Document Frequency)의 역수를 활용하여\n",
        "# 어떠한 단어가 얼마나 중요한지를 나타낸 통계적 수치이다.\n",
        "# 문서에서 자주 나오는 단어에 높은 가중치를 주되, 모든 문서에서 자주 나타나는 단어에 대해선 패널티를 주는 방식으로 값을 부여한다.\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(analyzer='word', min_df=1)\n",
        "train_idf = tfidf_vec.fit_transform(raw_documents=content)\n",
        "print(train_idf)\n",
        "print(tfidf_vec.get_feature_names_out())  # 건수가 아니라 건수에 대한 확률값을 출력(비율을 이용해 카운팅함)\n",
        "print(train_idf.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8RiExT8LVfr",
        "outputId": "98a87002-13cb-4d58-a189-5eaafd7add2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t0.3347122780719073\n",
            "  (0, 2)\t0.3347122780719073\n",
            "  (0, 4)\t0.4704264280854632\n",
            "  (0, 1)\t0.3347122780719073\n",
            "  (0, 6)\t0.4704264280854632\n",
            "  (0, 3)\t0.4704264280854632\n",
            "  (1, 5)\t0.4976748316029239\n",
            "  (1, 0)\t0.3540997415957358\n",
            "  (1, 2)\t0.3540997415957358\n",
            "  (1, 1)\t0.7081994831914716\n",
            "['disk' 'format' 'hard' 'how' 'my' 'problems' 'to']\n",
            "[[0.33471228 0.33471228 0.33471228 0.47042643 0.47042643 0.\n",
            "  0.47042643]\n",
            " [0.35409974 0.70819948 0.35409974 0.         0.         0.49767483\n",
            "  0.        ]]\n"
          ]
        }
      ]
    }
  ]
}