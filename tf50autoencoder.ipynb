{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwBHwlasYLLFJ5Su1LqC/h"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M7_DSaV63UZ0"
      },
      "outputs": [],
      "source": [
        "# Auto Encoder란 입력 데이터를 압축시켜 압축시킨 데이터로 축소한 후 다시 확장하여 결과 데이터를 입력 데이터와 동일하도록 만드는 일종의 딥 뉴럴 네트워크 모델이다.\n",
        "# Dense 만 사용해서 모델 작성\n",
        "# MNNIST dataset 사용\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_autoencoder(encoding_dim=32, image_shape=(784,)):\n",
        "    # encoder\n",
        "    input_img = Input(shape=image_shape)\n",
        "    encoded = Dense(32, activation='relu')(input_img)\n",
        "    encoded = Dense(64, activation='relu')(encoded)\n",
        "    encoded = Dense(128, activation='relu')(encoded)\n",
        "\n",
        "    # decoder\n",
        "    decoded = Dense(64, activation='sigmoid')(encoded)\n",
        "    decoded = Dense(128, activation='sigmoid')(decoded)  # Corrected line\n",
        "    decoded = Dense(image_shape[0], activation='sigmoid')(decoded)\n",
        "\n",
        "    # autoencoder model\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    print(autoencoder.summary())\n",
        "    encoder = Model(input_img, encoded)\n",
        "\n",
        "    # decoder model\n",
        "    encoded_input = Input(shape=(encoding_dim,))\n",
        "    decoder_layer = autoencoder.layers[-3](encoded_input)\n",
        "    decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
        "    decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
        "    decoder = Model(encoded_input, decoder_layer)\n",
        "    print(decoder.summary())\n",
        "\n",
        "    return autoencoder, encoder, decoder\n",
        "\n",
        "def prepare_data():\n",
        "  (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()  # 비지도 학습이니 label은 필요없음 그래서 '_' 로 함\n",
        "  x_train = x_train.astype('float32') / 255.\n",
        "  x_test = x_test.astype('float32') / 255.\n",
        "  x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "  x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "  print(x_train.shape, ' ', x_test.shape)\n",
        "  return x_train, x_test\n",
        "\n",
        "def display_images(original, reconstructed, n = 10):\n",
        "  plt.figure(figsize=(20,4))\n",
        "  for i in range(n):\n",
        "    # original\n",
        "    ax = plt.subplot(2, n, i + 1) # 2행 10열 1~10\n",
        "    plt.imshow(original[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # reconstructed\n",
        "    ax = plt.subplot(2, n, i + 1) # 2행 10열 1~10\n",
        "    plt.imshow(reconstructed[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "WTZvUlRk9JL_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  encoding_dim = 32\n",
        "  autoencoder, encoder, decoder = create_autoencoder(encoding_dim)\n",
        "  autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "  x_train, x_test = prepare_data()\n",
        "\n",
        "  autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test), verbose=2)\n",
        "\n",
        "  encoded_img = encoder.predict(x_test)\n",
        "  decoded_img = decoder.predict(encoded_img)\n",
        "\n",
        "  display_images(x_test, decoded_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "bhybuWAo9dKe",
        "outputId": "50909cc4-ef1c-4365-bc1b-c9f5fff0eff2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 784)               101136    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153264 (598.69 KB)\n",
            "Trainable params: 153264 (598.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-993d8a412ae2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mencoding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d510e896103e>\u001b[0m in \u001b[0;36mcreate_autoencoder\u001b[0;34m(encoding_dim, image_shape)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1018\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"dense_31\" (type Dense).\n\nDimensions must be equal, but are 32 and 128 for '{{node dense_31/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_31/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,64].\n\nCall arguments received by layer \"dense_31\" (type Dense):\n  • inputs=tf.Tensor(shape=(None, 32), dtype=float32)"
          ]
        }
      ]
    }
  ]
}