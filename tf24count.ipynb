{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvH04aW8JWDwgzgrp9wGl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoho0529/TensorFlow/blob/main/tf24count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KOvUswy3PtWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eec9e26-ed14-4fd4-a905-9679c6b1be24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고프다' '공부' '내일' '먹지' '배가' '아니' '점심' '점심먹고' '해야겠다' '해야지']\n",
            "{'고프다': 0, '아니': 5, '배가': 4, '내일': 2, '점심': 6, '먹지': 3, '공부': 1, '해야겠다': 8, '점심먹고': 7, '해야지': 9}\n",
            "['나는 배 고프다 아니 배가 고프다.']\n",
            "  (0, 0)\t2\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "[[2 0 0 0 1 1 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# 자연어 처리에서 특징추출 이란 단어나 문장들을 어떤 특징 값으로 변환하는 것을 의미한다.\n",
        "# 문자로 구성된 데이터를 모델에 적용할 수 있도록 특징을 추출해 수치화한다.\n",
        "# 단어의 수를 파악해 문장을 분석하는 방법\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "textData = ['나는 배 고프다 아니 배가 고프다.', '내일 점심 뭐 먹지?', '내일 공부 해야겠다.', '점심먹고 공부 해야지!']\n",
        "count_vec = CountVectorizer(analyzer='word', ngram_range=(1,1), stop_words=['나는'])  # ngram_range:단어장 생성에 사용할 토큰 크기를 결정\n",
        "count_vec.fit(textData)\n",
        "print(count_vec.get_feature_names_out())  # konlpy를 사용하면 조사,형용사 등 뺄 수 있음\n",
        "print(count_vec.vocabulary_)  # 사전 순으로 인덱싱\n",
        "print([textData[0]])\n",
        "sentence = [textData[0]]\n",
        "print(count_vec.transform(sentence))  # 0행에서 '고프다' 2번, 0행에서 '배' 1번, 0행에서 '아니' 1번  | 벡터화\n",
        "print(count_vec.transform(sentence).toarray())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF(Term Frequency(1개의 문장 내 특정 단어 등장빈도) - Inverse Document Frequency(DF:특정 단어가 나타나는 문장 수))\n",
        "# 정보 검색과 텍스트 마이닝에서 이용하는 가중치로, 여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치이다.\n",
        "# 단순히 빈도수로 그 단어의 가치를 정하는 것이 아니라, 여러 문장에 많이 등장하는 단어는 패널티를 주어 단어 빈도의 scale을 맞추는 기법\n",
        "# 즉, 분별력 있는 특징을 만들어준다.\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "textData = ['나는 배 고프다 아니 배가 고프다.', '내일 점심 뭐 먹지?', '내일 공부 해야겠다.', '점심먹고 공부 해야지!']\n",
        "tfidf_vec = TfidfVectorizer(analyzer='word', ngram_range=(1,1), stop_words=['나는'])\n",
        "tfidf_vec.fit(textData)\n",
        "print(tfidf_vec.get_feature_names_out())\n",
        "print(tfidf_vec.vocabulary_)\n",
        "print(tfidf_vec.transform(textData).toarray())  # 확률값으로 나옴\n",
        "print()\n",
        "sentence = [textData[3]]\n",
        "print(sentence)\n",
        "print(tfidf_vec.transform(sentence))\n",
        "print(tfidf_vec.transform(sentence).toarray()) # 먹고,해야지가 점심 공부 보다 중요하다고 판단"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWHAnTqDWbS5",
        "outputId": "049327fd-e5ab-40d2-aa46-cc9a40ce8a25"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['고프다' '공부' '내일' '먹지' '배가' '아니' '점심' '점심먹고' '해야겠다' '해야지']\n",
            "{'고프다': 0, '아니': 5, '배가': 4, '내일': 2, '점심': 6, '먹지': 3, '공부': 1, '해야겠다': 8, '점심먹고': 7, '해야지': 9}\n",
            "[[0.81649658 0.         0.         0.         0.40824829 0.40824829\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.48693426 0.61761437 0.         0.\n",
            "  0.61761437 0.         0.         0.        ]\n",
            " [0.         0.52640543 0.52640543 0.         0.         0.\n",
            "  0.         0.         0.66767854 0.        ]\n",
            " [0.         0.48693426 0.         0.         0.         0.\n",
            "  0.         0.61761437 0.         0.61761437]]\n",
            "\n",
            "['점심먹고 공부 해야지!']\n",
            "  (0, 9)\t0.6176143709756019\n",
            "  (0, 7)\t0.6176143709756019\n",
            "  (0, 1)\t0.48693426407352264\n",
            "[[0.         0.48693426 0.         0.         0.         0.\n",
            "  0.         0.61761437 0.         0.61761437]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidVectorizer를 사용해 텍스트(형태소 분석기 Okt를 적용)를 벡터로 변환 후 단어 간 유사도 계산\n",
        "# pip install konlpy\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qabmrh-GdBtc",
        "outputId": "f1b19c0f-b0b7-49ef-ad72-68dbebdf8deb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "def tokenizeFunc(ss):   # 형태소 분석용 함수\n",
        "  ss = okt.normalize(ss) # Okt는 정규화를 일부 지원함. ex)'사랑햌' -> '사랑해'로 수정\n",
        "  ss = okt.morphs(ss)    # 형태소 단위로 분리, 반환형은 리스트\n",
        "  return ss\n",
        "\n",
        "texts = ['길동이는 파이썬을 좋아합니다','길동이는 웹을 잘합니다','길동이는 운동을 매우 잘합니다']\n",
        "new_texts = ['길동이는 파이썬을 좋아하고 운동을 잘합니다']\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizeFunc, token_pattern=None).fit(texts)\n",
        "tfidf_matrix = tfidf.fit_transform(texts)\n",
        "print(tfidf_matrix)\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN4LFWFndum0",
        "outputId": "90e55b29-7ebd-48f8-909d-5a766d8648ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 8)\t0.5427006131762078\n",
            "  (0, 5)\t0.32052772458725637\n",
            "  (0, 9)\t0.5427006131762078\n",
            "  (0, 1)\t0.32052772458725637\n",
            "  (0, 6)\t0.32052772458725637\n",
            "  (0, 0)\t0.32052772458725637\n",
            "  (1, 10)\t0.40352535506797127\n",
            "  (1, 7)\t0.40352535506797127\n",
            "  (1, 4)\t0.5305873490316616\n",
            "  (1, 5)\t0.31337343564910264\n",
            "  (1, 1)\t0.31337343564910264\n",
            "  (1, 6)\t0.31337343564910264\n",
            "  (1, 0)\t0.31337343564910264\n",
            "  (2, 2)\t0.4686986463592043\n",
            "  (2, 3)\t0.4686986463592043\n",
            "  (2, 10)\t0.356457401476207\n",
            "  (2, 7)\t0.356457401476207\n",
            "  (2, 5)\t0.27682097087637686\n",
            "  (2, 1)\t0.27682097087637686\n",
            "  (2, 6)\t0.27682097087637686\n",
            "  (2, 0)\t0.27682097087637686\n",
            "[[0.32052772 0.32052772 0.         0.         0.         0.32052772\n",
            "  0.32052772 0.         0.54270061 0.54270061 0.        ]\n",
            " [0.31337344 0.31337344 0.         0.         0.53058735 0.31337344\n",
            "  0.31337344 0.40352536 0.         0.         0.40352536]\n",
            " [0.27682097 0.27682097 0.46869865 0.46869865 0.         0.27682097\n",
            "  0.27682097 0.3564574  0.         0.         0.3564574 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ntext in new_texts:\n",
        "  tftrans = tfidf.transform([ntext])  # 새로운 문장을 벡터로 변환\n",
        "  print('tftrans : \\n', tftrans)\n",
        "  # 새로운 문장과 기존 문장들 사이의 코사인 유사도 계산(데이터 크기 차이에 관계없이 계산)\n",
        "  cosine_simil = cosine_similarity(tftrans, tfidf_matrix)\n",
        "  print('cosine_simil : ', cosine_simil)  # [[0.6294     0.65051252 0.77272178]]\n",
        "\n",
        "  # 출력\n",
        "  print(f'새로운 문장 : {ntext}')\n",
        "  print('------------')\n",
        "  print(f'기존 문장 : ')\n",
        "  for idx in range(3):  # 기존문장이 3개니까 3개\n",
        "    # print(cosine_simil.argsort()[0])  # 새로운 문장과 기존 문장 3개를 비교, [0]은 2차원 배열의 0행을 의미\n",
        "    # print((idx + 1) * -1)\n",
        "    print(cosine_simil[0][(idx + 1) * -1])\n",
        "    most_simil_idx = cosine_simil.argsort()[0][(idx + 1) * -1]\n",
        "    print(most_simil_idx)\n",
        "    most_simil_sentence = texts[most_simil_idx]\n",
        "    simil_score = cosine_simil[0][most_simil_idx]\n",
        "    print(f'{most_simil_sentence} (유사도:{simil_score:.3f})')\n",
        "  print()\n",
        "\n",
        "  # 순서가 있는 자연어 데이터를 통해 문장생성, 챗봇, 문서 요약, 이미지 설명, 주식예측, 문장을 소리로 변역 ...을 하려면 RNN을 사"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb_2nEQDgkNY",
        "outputId": "fadce0e6-2401-4a2d-ca4c-7a13db5d7e9c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tftrans : \n",
            "   (0, 10)\t0.3214212466114349\n",
            "  (0, 9)\t0.4226303131144919\n",
            "  (0, 7)\t0.3214212466114349\n",
            "  (0, 6)\t0.2496122711403758\n",
            "  (0, 5)\t0.4992245422807516\n",
            "  (0, 3)\t0.4226303131144919\n",
            "  (0, 1)\t0.2496122711403758\n",
            "  (0, 0)\t0.2496122711403758\n",
            "cosine_simil :  [[0.6294     0.65051252 0.77272178]]\n",
            "새로운 문장 : 길동이는 파이썬을 좋아하고 운동을 잘합니다\n",
            "------------\n",
            "기존 문장 : \n",
            "0.7727217765585208\n",
            "2\n",
            "길동이는 운동을 매우 잘합니다 (유사도:0.773)\n",
            "0.6505125202677131\n",
            "1\n",
            "길동이는 웹을 잘합니다 (유사도:0.651)\n",
            "0.6293999965624972\n",
            "0\n",
            "길동이는 파이썬을 좋아합니다 (유사도:0.629)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}